{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://github.com/mateuszbuda/brain-segmentation-pytorch/archive/master.zip\" to /home/jackson/.cache/torch/hub/master.zip\n",
      "Downloading: \"https://github.com/mateuszbuda/brain-segmentation-pytorch/releases/download/v1.0/unet-e012d006.pt\" to /home/jackson/.cache/torch/hub/checkpoints/unet-e012d006.pt\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "model = torch.hub.load('mateuszbuda/brain-segmentation-pytorch', 'unet',\n",
    "    in_channels=3, out_channels=1, init_features=32, pretrained=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "import urllib\n",
    "url, filename = (\"https://github.com/mateuszbuda/brain-segmentation-pytorch/raw/master/assets/TCGA_CS_4944.png\", \"TCGA_CS_4944.png\")\n",
    "try:\n",
    "    urllib.URLopener().retrieve(url, filename)\n",
    "except:\n",
    "    urllib.request.urlretrieve(url, filename)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/shared/code/damp_lab/beholder/.venv/lib/python3.8/site-packages/torch/cuda/__init__.py:52: UserWarning: CUDA initialization: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx (Triggered internally at  /pytorch/c10/cuda/CUDAFunctions.cpp:100.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]]])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "\n",
    "input_image = Image.open(filename)\n",
    "m, s = np.mean(input_image, axis=(0, 1)), np.std(input_image, axis=(0, 1))\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=m, std=s),\n",
    "])\n",
    "input_tensor = preprocess(input_image)\n",
    "input_batch = input_tensor.unsqueeze(0)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    input_batch = input_batch.to('cuda')\n",
    "    model = model.to('cuda')\n",
    "\n",
    "with torch.no_grad():\n",
    "    output = model(input_batch)\n",
    "\n",
    "print(torch.round(output[0]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "[[0, 61, 122, 182, 243, 304, 365, 426, 486, 547, 608, 669, 730, 790, 851, 912],\n [0,\n  63,\n  126,\n  190,\n  253,\n  316,\n  379,\n  442,\n  506,\n  569,\n  632,\n  695,\n  758,\n  822,\n  885,\n  948,\n  1011,\n  1074,\n  1138,\n  1201,\n  1264]]"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_fp = \"small.jpeg\"\n",
    "\n",
    "from nnunet.network_architecture.neural_network import SegmentationNetwork\n",
    "test_image = np.array(Image.open(image_fp))\n",
    "image_size = test_image.shape\n",
    "patch_size = (128, 128)\n",
    "step_size = 0.5\n",
    "SegmentationNetwork._compute_steps_for_sliding_window(patch_size, image_size, step_size)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from batchgenerators.utilities.file_and_folder_operations import *\n",
    "from nnunet.dataset_conversion.utils import generate_dataset_json\n",
    "from nnunet.paths import nnUNet_raw_data, preprocessing_output_dir\n",
    "from nnunet.utilities.file_conversions import convert_2d_image_to_nifti\n",
    "\n",
    "\"\"\"\n",
    "nnU-Net was originally built for 3D images. It is also strongest when applied to 3D segmentation problems because a\n",
    "large proportion of its design choices were built with 3D in mind. Also note that many 2D segmentation problems,\n",
    "especially in the non-biomedical domain, may benefit from pretrained network architectures which nnU-Net does not\n",
    "support.\n",
    "Still, there is certainly a need for an out of the box segmentation solution for 2D segmentation problems. And\n",
    "also on 2D segmentation tasks nnU-Net cam perform extremely well! We have, for example, won a 2D task in the cell\n",
    "tracking challenge with nnU-Net (see our Nature Methods paper) and we have also successfully applied nnU-Net to\n",
    "histopathological segmentation problems.\n",
    "Working with 2D data in nnU-Net requires a small workaround in the creation of the dataset. Essentially, all images\n",
    "must be converted to pseudo 3D images (so an image with shape (X, Y) needs to be converted to an image with shape\n",
    "(1, X, Y). The resulting image must be saved in nifti format. Hereby it is important to set the spacing of the\n",
    "first axis (the one with shape 1) to a value larger than the others. If you are working with niftis anyways, then\n",
    "doing this should be easy for you. This example here is intended for demonstrating how nnU-Net can be used with\n",
    "'regular' 2D images. We selected the massachusetts road segmentation dataset for this because it can be obtained\n",
    "easily, it comes with a good amount of training cases but is still not too large to be difficult to handle.\n",
    "\"\"\"\n",
    "\n",
    "# download dataset from https://www.kaggle.com/insaff/massachusetts-roads-dataset\n",
    "# extract the zip file, then set the following path according to your system:\n",
    "base = '/media/prime/initial'\n",
    "# this folder should have the training and testing subfolders\n",
    "\n",
    "# now start the conversion to nnU-Net:\n",
    "task_name = 'Task256_MicrofluidicCell'\n",
    "target_base = join(nnUNet_raw_data, task_name)\n",
    "target_imagesTr = join(target_base, \"imagesTr\")\n",
    "target_imagesTs = join(target_base, \"imagesTs\")\n",
    "target_labelsTs = join(target_base, \"labelsTs\")\n",
    "target_labelsTr = join(target_base, \"labelsTr\")\n",
    "\n",
    "maybe_mkdir_p(target_imagesTr)\n",
    "maybe_mkdir_p(target_labelsTs)\n",
    "maybe_mkdir_p(target_imagesTs)\n",
    "maybe_mkdir_p(target_labelsTr)\n",
    "\n",
    "# convert the training examples. Not all training images have labels, so we just take the cases for which there are\n",
    "# labels\n",
    "labels_dir_tr = join(base, 'training', 'output')\n",
    "images_dir_tr = join(base, 'training', 'input')\n",
    "training_cases = subfiles(labels_dir_tr, suffix='.png', join=False)\n",
    "for t in training_cases:\n",
    "    unique_name = t[:-4]  # just the filename with the extension cropped away, so img-2.png becomes img-2 as unique_name\n",
    "    input_segmentation_file = join(labels_dir_tr, t)\n",
    "    input_image_file = join(images_dir_tr, t)\n",
    "\n",
    "    output_image_file = join(target_imagesTr, unique_name)  # do not specify a file ending! This will be done for you\n",
    "    output_seg_file = join(target_labelsTr, unique_name)  # do not specify a file ending! This will be done for you\n",
    "\n",
    "    # this utility will convert 2d images that can be read by skimage.io.imread to nifti. You don't need to do anything.\n",
    "    # if this throws an error for your images, please just look at the code for this function and adapt it to your needs\n",
    "    convert_2d_image_to_nifti(input_image_file, output_image_file, is_seg=False)\n",
    "\n",
    "    # the labels are stored as 0: background, 255: road. We need to convert the 255 to 1 because nnU-Net expects\n",
    "    # the labels to be consecutive integers. This can be achieved with setting a transform\n",
    "    convert_2d_image_to_nifti(input_segmentation_file, output_seg_file, is_seg=True,\n",
    "                              transform=lambda x: (x == 255).astype(int))\n",
    "\n",
    "# now do the same for the test set\n",
    "labels_dir_ts = join(base, 'testing', 'output')\n",
    "images_dir_ts = join(base, 'testing', 'input')\n",
    "testing_cases = subfiles(labels_dir_ts, suffix='.png', join=False)\n",
    "for ts in testing_cases:\n",
    "    unique_name = ts[:-4]\n",
    "    input_segmentation_file = join(labels_dir_ts, ts)\n",
    "    input_image_file = join(images_dir_ts, ts)\n",
    "\n",
    "    output_image_file = join(target_imagesTs, unique_name)\n",
    "    output_seg_file = join(target_labelsTs, unique_name)\n",
    "\n",
    "    convert_2d_image_to_nifti(input_image_file, output_image_file, is_seg=False)\n",
    "    convert_2d_image_to_nifti(input_segmentation_file, output_seg_file, is_seg=True,\n",
    "                              transform=lambda x: (x == 255).astype(int))\n",
    "\n",
    "# finally we can call the utility for generating a dataset.json\n",
    "generate_dataset_json(join(target_base, 'dataset.json'), target_imagesTr, target_imagesTs, ('Red', 'Green', 'Blue'),\n",
    "                      labels={1: 'street'}, dataset_name=task_name, license='hands off!')\n",
    "\n",
    "\"\"\"\n",
    "once this is completed, you can use the dataset like any other nnU-Net dataset. Note that since this is a 2D\n",
    "dataset there is no need to run preprocessing for 3D U-Nets. You should therefore run the\n",
    "`nnUNet_plan_and_preprocess` command like this:\n",
    "\n",
    "> nnUNet_plan_and_preprocess -t 120 -pl3d None\n",
    "\n",
    "once that is completed, you can run the trainings as follows:\n",
    "> nnUNet_train 2d nnUNetTrainerV2 120 FOLD\n",
    "\n",
    "(where fold is again 0, 1, 2, 3 and 4 - 5-fold cross validation)\n",
    "\n",
    "there is no need to run nnUNet_find_best_configuration because there is only one model to shoose from.\n",
    "Note that without running nnUNet_find_best_configuration, nnU-Net will not have determined a postprocessing\n",
    "for the whole cross-validation. Spoiler: it will determine not to run postprocessing anyways. If you are using\n",
    "a different 2D dataset, you can make nnU-Net determine the postprocessing by using the\n",
    "`nnUNet_determine_postprocessing` command\n",
    "\"\"\"\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}