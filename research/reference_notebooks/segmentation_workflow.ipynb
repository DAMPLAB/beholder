{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import random as rng\n",
    "\n",
    "import imageio\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from skimage import exposure\n",
    "from skimage import filters\n",
    "import cv2\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Grab an ND2 File and take the first image off of it.\n",
    "import nd2reader\n",
    "from pims import ND2_Reader as nd2_sdk\n",
    "\n",
    "INPUT_FILE = \"../data/agarose_pads/SR15_1mM_IPTG_Agarose_TS_1h_1.nd2\"\n",
    "\n",
    "def get_raw():\n",
    "    with nd2reader.ND2Reader(INPUT_FILE) as input_frames:\n",
    "        return input_frames[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_frame(input_frame):\n",
    "    plt.imshow(\n",
    "        input_frame,\n",
    "        cmap='gray',\n",
    "        interpolation='nearest',\n",
    "    )\n",
    "\n",
    "def downsample_image(input_frame: np.ndarray) -> np.ndarray:\n",
    "    '''\n",
    "    Downsamples a 16bit input image to an 8bit image. Will result in loss\n",
    "    of signal fidelity due to loss of precision.\n",
    "\n",
    "    Args:\n",
    "        input_frame: Input numpy array\n",
    "\n",
    "    Returns:\n",
    "        Downsampled ndarray\n",
    "    '''\n",
    "    return (input_frame / 256).astype('uint8')\n",
    "\n",
    "def downsample(input_frame):\n",
    "    return (255 * input_frame / np.max(input_frame)).astype(np.uint8)\n",
    "\n",
    "def threshold(input_frame, low=2, high=98):\n",
    "    low_threshold = np.percentile(input_frame, low)\n",
    "    high_threshold = np.percentile(input_frame, high)\n",
    "    ret, thresh = cv2.threshold(input_frame, low_threshold, high_threshold, 0)\n",
    "    return thresh\n",
    "\n",
    "def invert_image(input_frame):\n",
    "    return np.invert(input_frame)\n",
    "\n",
    "def remove_background(input_frame, adjustment: float = 1.0):\n",
    "    background_level = np.mean(input_frame) * adjustment\n",
    "    return input_frame - background_level\n",
    "\n",
    "def kernel(input_frame):\n",
    "    kernel = np.array([[-1,-1,-1], [-1,9,-1], [-1,-1,-1]])\n",
    "    return cv2.filter2D(input_frame, -1, kernel)\n",
    "\n",
    "def unsharp_mask(image, kernel_size=(5, 5), sigma=1.0, amount=1.0, threshold=0):\n",
    "    \"\"\"Return a sharpened version of the image, using an unsharp mask.\"\"\"\n",
    "    blurred = cv2.GaussianBlur(image, kernel_size, sigma)\n",
    "    sharpened = float(amount + 1) * image - float(amount) * blurred\n",
    "    sharpened = np.maximum(sharpened, np.zeros(sharpened.shape))\n",
    "    sharpened = np.minimum(sharpened, 255 * np.ones(sharpened.shape))\n",
    "    sharpened = sharpened.round().astype(np.uint8)\n",
    "    if threshold > 0:\n",
    "        low_contrast_mask = np.absolute(image - blurred) < threshold\n",
    "        np.copyto(sharpened, image, where=low_contrast_mask)\n",
    "    return sharpened\n",
    "\n",
    "\n",
    "def find_countours(input_frame):\n",
    "    inner_contours, hierarchy = cv2.findContours(\n",
    "        input_frame,\n",
    "        cv2.RETR_TREE,\n",
    "        cv2.CHAIN_APPROX_NONE,\n",
    "    )\n",
    "    return inner_contours\n",
    "\n",
    "def draw_convex_hull(edges, contours):\n",
    "        # Find the convex hull object for each contour\n",
    "        hull_list = []\n",
    "        for i in range(len(contours)):\n",
    "            hull = cv2.convexHull(contours[i])\n",
    "            hull_list.append(hull)\n",
    "        # Draw contours + hull results\n",
    "        drawing = np.zeros((edges.shape[0], edges.shape[1], 3), dtype=np.uint8)\n",
    "        for i in range(len(contours)):\n",
    "            color = (rng.randint(0,256), rng.randint(0,256), rng.randint(0,256))\n",
    "            cv2.drawContours(drawing, contours, i, color)\n",
    "            cv2.drawContours(drawing, hull_list, i, color)\n",
    "        return drawing\n",
    "\n",
    "def gaussian_blur(input_frame, kernel: int=3):\n",
    "    return cv2.GaussianBlur(input_frame, (kernel, kernel), 0)\n",
    "\n",
    "def laplacian_operator(input_frame):\n",
    "    return cv2.Laplacian(input_frame, cv2.CV_64F, ksize=3)\n",
    "\n",
    "def otsu_thresholding(input_frame):\n",
    "    blur = cv2.GaussianBlur(input_frame,(3,3),0)\n",
    "    ret3,th3 = cv2.threshold(blur,0,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "    return th3\n",
    "\n",
    "def auto_canny(image, sigma=0.01):\n",
    "\t# compute the median of the single channel pixel intensities\n",
    "\tv = np.median(image)\n",
    "\t# apply automatic Canny edge detection using the computed median\n",
    "\tlower = int(max(0, (1.0 - sigma) * v))\n",
    "\tupper = int(min(255, (1.0 + sigma) * v))\n",
    "\treturn cv2.Canny(image, lower, upper)\n",
    "\n",
    "def pyramid_mean_shift(input_frame, lower=21, upper=51):\n",
    "    return cv2.pyrMeanShiftFiltering(input_frame, lower, upper)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8192.0\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def watershed_approach():\n",
    "    gray = get_raw()\n",
    "    # gray = unsharp_mask(gray)\n",
    "    # ret, thresh = cv2.threshold(gray,0,255,cv2.THRESH_BINARY_INV+cv2.THRESH_OTSU)\n",
    "    thresh = threshold(gray)\n",
    "    thresh = invert_image(thresh)\n",
    "    kernel = np.ones((3,3),np.uint8)\n",
    "    opening = cv2.morphologyEx(thresh,cv2.MORPH_OPEN,kernel, iterations = 2)\n",
    "\n",
    "    sure_bg = cv2.dilate(opening,kernel,iterations=3)\n",
    "    dist_transform = cv2.distanceTransform(downsample_image(opening) ,cv2.DIST_C,0)\n",
    "    print(dist_transform.max())\n",
    "    ret, sure_fg = cv2.threshold(dist_transform,0.7*dist_transform.max(),255,0)\n",
    "    sure_fg = np.uint8(sure_fg)\n",
    "    unknown = cv2.subtract(downsample_image(sure_bg),sure_fg)\n",
    "    display_frame(unknown)\n",
    "\n",
    "watershed_approach()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "outputs": [
    {
     "data": {
      "text/plain": "interactive(children=(IntSlider(value=2, description='low_threshold'), IntSlider(value=98, description='high_t…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "82c5364010e84a2eb8d74300502c83e3"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display\n",
    "from ipywidgets import IntSlider\n",
    "@interact(low_threshold = IntSlider(min=0, max=100, step=1, value=2), high_threshold=IntSlider(min=0, max=200, step=1, value=98))\n",
    "def attempt_2(low_threshold, high_threshold):\n",
    "    out = get_raw()\n",
    "    # out = laplacian_operator(out)\n",
    "    mask = np.zeros_like(out)\n",
    "    out = remove_background(invert_image(threshold(out, low_threshold, high_threshold)), 1)\n",
    "    out = downsample_image(out)\n",
    "    # out = cv2.Canny(out, low_threshold, high_threshold)\n",
    "    contours, hierarchy = cv2.findContours(out, cv2.RETR_TREE, cv2.CHAIN_APPROX_NONE)\n",
    "    contour_areas = map(cv2.contourArea, contours)\n",
    "    hist, bin_edges = np.histogram(contour_areas, bins=10)\n",
    "    out = cv2.drawContours(mask, contours, -1, (255, 255, 255), -1)\n",
    "    display_frame(out)\n",
    "## So, what we need to do is:\n",
    "#   1) Filter detrius from the resultant contours by summating all the median areas of the\n",
    "#   other contours and creating a low-pass filter from the histogram bins.\n",
    "#\n",
    "#   2) Once you are good to go on that, we need to figure out how you can take a contour\n",
    "#   area and use it as a way to calculate mean fluroesence in the green/red channels.\n",
    "#\n",
    "#   3) We then need to be able to take it and apply it to the videos.\n",
    "#\n",
    "#   4) We then need to generate some of the charts that Sam required.\n",
    "#\n",
    "#   5) We then need to refine our approach in terms of segmentation either via eroding\n",
    "#   or some other mechanism."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from ipywidgets import IntSlider\n",
    "@interact(low_threshold = IntSlider(min=0, max=100, step=1, value=2), high_threshold=IntSlider(min=0, max=100, step=1, value=98))\n",
    "def percentile_thresholding(low_threshold, high_threshold):\n",
    "    input_image = get_raw()\n",
    "    out_image = threshold(input_image, low_threshold, high_threshold)\n",
    "    display_frame(out_image)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "@interact(canny_low_one=140, canny_high_one=210)\n",
    "def canny_testing(canny_low_one, canny_high_one):\n",
    "    print(1)\n",
    "    _input_image = get_raw()\n",
    "    _out_image = threshold(_input_image, 2, 98)\n",
    "    edge = cv2.Canny(_out_image, canny_low_one, canny_high_one)\n",
    "    # Chain Approx None is very important due to the amorphous nature of the\n",
    "    # underlying cells.\n",
    "    contours, hierarchy = cv2.findContours(edge, cv2.RETR_LIST, cv2.CHAIN_APPROX_NONE)\n",
    "    for c in contours:\n",
    "        hull = cv2.convexHull(c)\n",
    "        cv2.drawContours(_out_image, [hull], 0, (0, 255, 0), 2)\n",
    "    display_frame(_out_image)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "@interact(canny_low=100, canny_high=100, do_threshold=True)\n",
    "def pipeline_experiment(canny_low, canny_high, do_threshold):\n",
    "    raw_frame = get_raw()\n",
    "    mask = np.zeros(raw_frame.shape, np.uint8)\n",
    "    carry_frame =  downsample_image(raw_frame)\n",
    "    if do_threshold:\n",
    "        carry_frame = threshold(carry_frame)\n",
    "    display_frame(unsharp_mask(carry_frame))\n",
    "    edges = cv2.Canny(carry_frame, canny_low, canny_high)\n",
    "    display_frame(edges)\n",
    "    contours = find_countours(edges)\n",
    "    # display_frame(draw_convex_hull(edges, contours))\n",
    "    # draw_convex_hull(edges, contours)\n",
    "    # display_frame(mask)\n",
    "    cv2.imwrite('test.jpg', mask)\n",
    "    raw_frame[mask == 255] = raw_frame[mask == 255]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "@interact(kernel_median= IntSlider(min=0, max=100, step=1, value=2, canny_high=100, do_threshold=True))\n",
    "def kernel_test(kernel_median):\n",
    "    input_frame = get_raw()\n",
    "    kernel = np.array([[-1,-1,-1], [-1,kernel_median,-1], [-1,-1,-1]])\n",
    "    display_frame(cv2.filter2D(input_frame, -1, kernel))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "@interact(kernel_median= IntSlider(min=0, max=100, step=1, value=2, canny_high=100, do_threshold=True))\n",
    "def billateral_filtering(kernel_median):\n",
    "    input_frame = get_raw()\n",
    "    kernel = np.array([[-1,-1,-1], [-1,kernel_median,-1], [-1,-1,-1]])\n",
    "    display_frame(cv2.filter2D(input_frame, -1, kernel))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "input_image = imageio.imread(example_file)\n",
    "val = filters.sobel(input_image)\n",
    "\n",
    "hist, bins_center = exposure.histogram(input_image)\n",
    "\n",
    "plt.figure(figsize=(9, 4))\n",
    "plt.subplot(131)\n",
    "plt.imshow(\n",
    "    input_image,\n",
    "    cmap='gray',\n",
    "    interpolation='nearest',\n",
    ")\n",
    "thresholded_array = input_image > val\n",
    "thresholded_array = np.logical_not(thresholded_array)\n",
    "plt.axis('off')\n",
    "plt.subplot(132)\n",
    "plt.imshow(\n",
    "    thresholded_array,\n",
    "    cmap='gray',\n",
    "    interpolation='nearest',\n",
    ")\n",
    "np.clip(input_image, 1689, 1690)\n",
    "plt.axis('off')\n",
    "plt.subplot(133)\n",
    "plt.plot(bins_center, hist, lw=2)\n",
    "plt.axvline(val, color='k', ls='--')\n",
    "\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}